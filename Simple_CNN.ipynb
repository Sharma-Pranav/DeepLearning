{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sharma-Pranav/DeepLearning/blob/master/Simple_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "HgWBwbrhuaAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fc899d8-17d7-4cdb-ca0e-5d5f3025139c"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wuVP1BF5vPmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "484d8957-4639-4dc3-a4c4-ccb33e3e4bce"
      },
      "cell_type": "code",
      "source": [
        "# Get the Dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kXwcph2cvbd1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  Reshape X_data from (n,28,28) to (n, 28, 28, 1)\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKGD1ZgYwMpX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# One Hot Encoding Y_data\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wNNAxmoawZa8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn():\n",
        "  'Creates a CNN every time this function is called'\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]), filters = 50, kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(50, activation = 'relu'))\n",
        "  model.add(Dense(10, activation = 'softmax'))\n",
        "  \n",
        "  adam = optimizers.Adam()\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4kAb5O0Xxp2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0d3fab2a-dbac-493e-de7d-a6bbc2bf095d"
      },
      "cell_type": "code",
      "source": [
        "model = cnn()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZvdZbpppxv6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3485
        },
        "outputId": "20bfb588-9ab4-472f-ef17-e5570836c5ab"
      },
      "cell_type": "code",
      "source": [
        "training_history = model.fit(X_train, Y_train, batch_size = 50, validation_split = 0.2, epochs = 100, verbose = 1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "48000/48000 [==============================] - 12s 256us/step - loss: 8.3853 - acc: 0.4743 - val_loss: 6.7397 - val_acc: 0.5757\n",
            "Epoch 2/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 1.3139 - acc: 0.8870 - val_loss: 0.1122 - val_acc: 0.9664\n",
            "Epoch 3/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0639 - acc: 0.9801 - val_loss: 0.0921 - val_acc: 0.9753\n",
            "Epoch 4/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0348 - acc: 0.9890 - val_loss: 0.0934 - val_acc: 0.9777\n",
            "Epoch 5/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0258 - acc: 0.9916 - val_loss: 0.0966 - val_acc: 0.9771\n",
            "Epoch 6/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.1005 - val_acc: 0.9779\n",
            "Epoch 7/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0195 - acc: 0.9936 - val_loss: 0.1221 - val_acc: 0.9778\n",
            "Epoch 8/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0186 - acc: 0.9942 - val_loss: 0.1443 - val_acc: 0.9735\n",
            "Epoch 9/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.1434 - val_acc: 0.9753\n",
            "Epoch 10/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.1512 - val_acc: 0.9743\n",
            "Epoch 11/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0118 - acc: 0.9966 - val_loss: 0.1439 - val_acc: 0.9782\n",
            "Epoch 12/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0156 - acc: 0.9955 - val_loss: 0.1453 - val_acc: 0.9769\n",
            "Epoch 13/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0153 - acc: 0.9959 - val_loss: 0.1698 - val_acc: 0.9763\n",
            "Epoch 14/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.1574 - val_acc: 0.9776\n",
            "Epoch 15/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0124 - acc: 0.9965 - val_loss: 0.1681 - val_acc: 0.9762\n",
            "Epoch 16/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0086 - acc: 0.9978 - val_loss: 0.1733 - val_acc: 0.9792\n",
            "Epoch 17/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0125 - acc: 0.9968 - val_loss: 0.1886 - val_acc: 0.9765\n",
            "Epoch 18/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.1749 - val_acc: 0.9788\n",
            "Epoch 19/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0109 - acc: 0.9973 - val_loss: 0.1683 - val_acc: 0.9793\n",
            "Epoch 20/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.1753 - val_acc: 0.9796\n",
            "Epoch 21/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.1870 - val_acc: 0.9782\n",
            "Epoch 22/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0094 - acc: 0.9980 - val_loss: 0.1739 - val_acc: 0.9793\n",
            "Epoch 23/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.1750 - val_acc: 0.9812\n",
            "Epoch 24/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0108 - acc: 0.9979 - val_loss: 0.1975 - val_acc: 0.9782\n",
            "Epoch 25/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0073 - acc: 0.9984 - val_loss: 0.1910 - val_acc: 0.9783\n",
            "Epoch 26/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0166 - acc: 0.9968 - val_loss: 0.2202 - val_acc: 0.9782\n",
            "Epoch 27/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0124 - acc: 0.9978 - val_loss: 0.2152 - val_acc: 0.9773\n",
            "Epoch 28/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0086 - acc: 0.9984 - val_loss: 0.2030 - val_acc: 0.9800\n",
            "Epoch 29/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0091 - acc: 0.9982 - val_loss: 0.2139 - val_acc: 0.9788\n",
            "Epoch 30/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.2214 - val_acc: 0.9782\n",
            "Epoch 31/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0091 - acc: 0.9984 - val_loss: 0.2125 - val_acc: 0.9809\n",
            "Epoch 32/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0131 - acc: 0.9979 - val_loss: 0.2554 - val_acc: 0.9764\n",
            "Epoch 33/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0081 - acc: 0.9986 - val_loss: 0.2283 - val_acc: 0.9788\n",
            "Epoch 34/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0107 - acc: 0.9981 - val_loss: 0.2219 - val_acc: 0.9804\n",
            "Epoch 35/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0097 - acc: 0.9984 - val_loss: 0.2580 - val_acc: 0.9769\n",
            "Epoch 36/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0074 - acc: 0.9988 - val_loss: 0.2370 - val_acc: 0.9790\n",
            "Epoch 37/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0063 - acc: 0.9989 - val_loss: 0.2268 - val_acc: 0.9797\n",
            "Epoch 38/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0127 - acc: 0.9980 - val_loss: 0.2403 - val_acc: 0.9793\n",
            "Epoch 39/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0102 - acc: 0.9985 - val_loss: 0.2523 - val_acc: 0.9774\n",
            "Epoch 40/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0088 - acc: 0.9986 - val_loss: 0.2415 - val_acc: 0.9802\n",
            "Epoch 41/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0099 - acc: 0.9987 - val_loss: 0.2642 - val_acc: 0.9763\n",
            "Epoch 42/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0132 - acc: 0.9980 - val_loss: 0.2658 - val_acc: 0.9767\n",
            "Epoch 43/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0131 - acc: 0.9983 - val_loss: 0.2441 - val_acc: 0.9803\n",
            "Epoch 44/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0102 - acc: 0.9985 - val_loss: 0.2435 - val_acc: 0.9793\n",
            "Epoch 45/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0093 - acc: 0.9988 - val_loss: 0.2506 - val_acc: 0.9795\n",
            "Epoch 46/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0099 - acc: 0.9986 - val_loss: 0.2478 - val_acc: 0.9800\n",
            "Epoch 47/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0122 - acc: 0.9987 - val_loss: 0.2538 - val_acc: 0.9802\n",
            "Epoch 48/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0143 - acc: 0.9984 - val_loss: 0.2633 - val_acc: 0.9774\n",
            "Epoch 49/100\n",
            "48000/48000 [==============================] - 8s 162us/step - loss: 0.0142 - acc: 0.9981 - val_loss: 0.2405 - val_acc: 0.9808\n",
            "Epoch 50/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0094 - acc: 0.9989 - val_loss: 0.2555 - val_acc: 0.9801\n",
            "Epoch 51/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0084 - acc: 0.9988 - val_loss: 0.2527 - val_acc: 0.9806\n",
            "Epoch 52/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0193 - acc: 0.9980 - val_loss: 0.2653 - val_acc: 0.9798\n",
            "Epoch 53/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0147 - acc: 0.9983 - val_loss: 0.2359 - val_acc: 0.9816\n",
            "Epoch 54/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0087 - acc: 0.9988 - val_loss: 0.2709 - val_acc: 0.9790\n",
            "Epoch 55/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0085 - acc: 0.9989 - val_loss: 0.2299 - val_acc: 0.9827\n",
            "Epoch 56/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0118 - acc: 0.9987 - val_loss: 0.2864 - val_acc: 0.9781\n",
            "Epoch 57/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0074 - acc: 0.9990 - val_loss: 0.2747 - val_acc: 0.9784\n",
            "Epoch 58/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0118 - acc: 0.9986 - val_loss: 0.2655 - val_acc: 0.9791\n",
            "Epoch 59/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0093 - acc: 0.9989 - val_loss: 0.2655 - val_acc: 0.9798\n",
            "Epoch 60/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0141 - acc: 0.9984 - val_loss: 0.2702 - val_acc: 0.9798\n",
            "Epoch 61/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0141 - acc: 0.9985 - val_loss: 0.2490 - val_acc: 0.9811\n",
            "Epoch 62/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0110 - acc: 0.9988 - val_loss: 0.2675 - val_acc: 0.9808\n",
            "Epoch 63/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0187 - acc: 0.9983 - val_loss: 0.2809 - val_acc: 0.9782\n",
            "Epoch 64/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0115 - acc: 0.9989 - val_loss: 0.2799 - val_acc: 0.9788\n",
            "Epoch 65/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0067 - acc: 0.9992 - val_loss: 0.2756 - val_acc: 0.9794\n",
            "Epoch 66/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0228 - acc: 0.9978 - val_loss: 0.2658 - val_acc: 0.9805\n",
            "Epoch 67/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0125 - acc: 0.9986 - val_loss: 0.2846 - val_acc: 0.9793\n",
            "Epoch 68/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0139 - acc: 0.9986 - val_loss: 0.2513 - val_acc: 0.9813\n",
            "Epoch 69/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0128 - acc: 0.9987 - val_loss: 0.2784 - val_acc: 0.9802\n",
            "Epoch 70/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0161 - acc: 0.9983 - val_loss: 0.2706 - val_acc: 0.9798\n",
            "Epoch 71/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0125 - acc: 0.9989 - val_loss: 0.2729 - val_acc: 0.9805\n",
            "Epoch 72/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0105 - acc: 0.9989 - val_loss: 0.2531 - val_acc: 0.9815\n",
            "Epoch 73/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0142 - acc: 0.9986 - val_loss: 0.2898 - val_acc: 0.9790\n",
            "Epoch 74/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0150 - acc: 0.9985 - val_loss: 0.2528 - val_acc: 0.9810\n",
            "Epoch 75/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0102 - acc: 0.9991 - val_loss: 0.2662 - val_acc: 0.9810\n",
            "Epoch 76/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0124 - acc: 0.9987 - val_loss: 0.2771 - val_acc: 0.9806\n",
            "Epoch 77/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0115 - acc: 0.9990 - val_loss: 0.2751 - val_acc: 0.9808\n",
            "Epoch 78/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0130 - acc: 0.9988 - val_loss: 0.2398 - val_acc: 0.9831\n",
            "Epoch 79/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0203 - acc: 0.9982 - val_loss: 0.2611 - val_acc: 0.9823\n",
            "Epoch 80/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0150 - acc: 0.9987 - val_loss: 0.2785 - val_acc: 0.9811\n",
            "Epoch 81/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0183 - acc: 0.9984 - val_loss: 0.3112 - val_acc: 0.9787\n",
            "Epoch 82/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0206 - acc: 0.9983 - val_loss: 0.2888 - val_acc: 0.9800\n",
            "Epoch 83/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0119 - acc: 0.9990 - val_loss: 0.2573 - val_acc: 0.9819\n",
            "Epoch 84/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0182 - acc: 0.9985 - val_loss: 0.2674 - val_acc: 0.9816\n",
            "Epoch 85/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0207 - acc: 0.9983 - val_loss: 0.2971 - val_acc: 0.9794\n",
            "Epoch 86/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0194 - acc: 0.9984 - val_loss: 0.2925 - val_acc: 0.9803\n",
            "Epoch 87/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0117 - acc: 0.9990 - val_loss: 0.2623 - val_acc: 0.9823\n",
            "Epoch 88/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0140 - acc: 0.9988 - val_loss: 0.2745 - val_acc: 0.9813\n",
            "Epoch 89/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0109 - acc: 0.9991 - val_loss: 0.2741 - val_acc: 0.9814\n",
            "Epoch 90/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0203 - acc: 0.9983 - val_loss: 0.2405 - val_acc: 0.9839\n",
            "Epoch 91/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0091 - acc: 0.9992 - val_loss: 0.2645 - val_acc: 0.9822\n",
            "Epoch 92/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.0180 - acc: 0.9986 - val_loss: 0.2788 - val_acc: 0.9808\n",
            "Epoch 93/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0218 - acc: 0.9981 - val_loss: 0.2674 - val_acc: 0.9819\n",
            "Epoch 94/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0214 - acc: 0.9984 - val_loss: 0.2791 - val_acc: 0.9810\n",
            "Epoch 95/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0174 - acc: 0.9987 - val_loss: 0.2489 - val_acc: 0.9829\n",
            "Epoch 96/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0164 - acc: 0.9987 - val_loss: 0.3003 - val_acc: 0.9794\n",
            "Epoch 97/100\n",
            "48000/48000 [==============================] - 8s 161us/step - loss: 0.0207 - acc: 0.9984 - val_loss: 0.2683 - val_acc: 0.9814\n",
            "Epoch 98/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0139 - acc: 0.9989 - val_loss: 0.2633 - val_acc: 0.9827\n",
            "Epoch 99/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0186 - acc: 0.9984 - val_loss: 0.2703 - val_acc: 0.9818\n",
            "Epoch 100/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.0125 - acc: 0.9990 - val_loss: 0.2371 - val_acc: 0.9832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TookrmuFyA8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "a41612aa-5ab9-465d-c1d3-a9d28b1b63f3"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(training_history.history['acc'])\n",
        "plt.plot(training_history.history['val_acc'])\n",
        "plt.legend(['training', 'validation'], loc = 'upper left')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc2001bbc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYQgTERGNEIYwERHRCGEIExERjZD/D5X5/xzyg++AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Nabk5kgays_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ecdf33c2-bc02-4182-c59c-2a1536b13d3b"
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(X_test, Y_test)\n",
        "print('Test Accuracy', results[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 72us/step\n",
            "Test Accuracy 0.9806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XRjehty35seE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}